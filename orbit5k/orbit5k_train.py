# -*- coding: utf-8 -*-
"""orbit5k_train

Automatically generated by Colaboratory.
"""

import numpy as np
import tensorflow.compat.v2 as tf
from sklearn.model_selection import train_test_split
import time

tf.enable_v2_behavior()
# tf.compat.v1.flags.DEFINE_string('f', '', 'kernel')

from pllay import *

"""# Training"""

nmax_diag = 69
# num_pts_per_orbit = 100
num_pts_per_orbit = 1000


class ORBIT5K_MLP(tf.keras.Model):
    def __init__(self, name='orbit5kmlp', unitsDense=32, **kwargs):
        super(ORBIT5K_MLP, self).__init__(name=name, **kwargs)
        # self.layer1 = TopoLayer(unitsTop, m0=0.01, tseq=np.linspace(0.03, 0.1, 17), KK=list(range(2)), dimensions = [0, 1], lims = [[0.0125, 0.9875], [0.0125, 0.9875]], by=0.025)
        self.layer2 = tf.keras.layers.Dense(unitsDense, activation='relu', name='dense_2') 
        self.layer3 = tf.keras.layers.Dense(5, name='predictions')

    def call(self, x):
        xp, xl, xd = tf.split(x, [2*num_pts_per_orbit, 102, 4*nmax_diag], axis=-1)
        # xl1 = tf.nn.relu(self.layer1(xl))
        # x = xl1
        # x = tf.concat((xp, xl1), -1)
        x = xp
        x = self.layer2(x)
        x = self.layer3(x)
        print(x.shape)
        return x


class ORBIT5K_MLP_PLLay(tf.keras.Model):
    def __init__(self, name='orbit5kmlppllay', unitsDense=32, unitsTop=64, **kwargs):
        super(ORBIT5K_MLP_PLLay, self).__init__(name=name, **kwargs)
        # self.layer1 = TopoLayer(unitsTop, m0=0.01, tseq=np.linspace(0.03, 0.1, 17), KK=list(range(2)), dimensions = [0, 1], lims = [[0.0125, 0.9875], [0.0125, 0.9875]], by=0.025)
        self.layer1 = GThetaLayer(unitsTop)
        self.layer2 = tf.keras.layers.Dense(unitsDense, activation='relu', name='dense_2') 
        self.layer3 = tf.keras.layers.Dense(5, name='predictions')

    def call(self, x):
        xp, xl, xd = tf.split(x, [2*num_pts_per_orbit, 102, 4*nmax_diag], axis=-1)
        xl1 = tf.nn.relu(self.layer1(xl))
        x = xl1
        # x = tf.concat((xp, xl1), -1)
        # x = xp
        x = self.layer2(x)
        x = self.layer3(x)
        print(x.shape)
        return x


class ORBIT5K_CNN(tf.keras.Model):
    def __init__(self, name='orbit5kcnnpllay', filters=32, kernel_size=4, unitsDense=64, **kwargs):
        super(ORBIT5K_CNN, self).__init__(**kwargs)
        self.layer1_1 = tf.keras.layers.Conv2D(filters, kernel_size, padding="same", activation='relu')
        self.layer1_2 = tf.keras.layers.Conv2D(1, kernel_size, padding="same", activation='relu')
        # self.layer1_3 = TopoFunLayer(unitsTopMiddle, grid_size=[40, 40], tseq=np.linspace(0.05, 0.95, 18), KK=list(range(2)), dimensions = [0, 1])
        # self.layer2 = TopoLayer(unitsTopInput, m0=0.02, tseq=np.linspace(0.03, 0.1, 17), KK=list(range(2)), dimensions = [0, 1], lims = [[0.0125, 0.9875], [0.0125, 0.9875]], by=0.025)
        self.layer3 = tf.keras.layers.Dense(unitsDense, activation='relu', name='dense_2') 
        self.layer4 = tf.keras.layers.Dense(5, name='predictions')

    def call(self, x):
        xg, xl, xd = tf.split(x, [1600, 102, 4*nmax_diag], axis=-1)
        xg = tf.reshape(xg, [16, 40, 40, 1])
        xg1 = self.layer1_1(xg)
        xg1 = self.layer1_2(xg1)
        xg1 = tf.reshape(xg1, [16, 1600])
        # xg1_1 = tf.nn.relu(self.layer1_3(xg1))
        # xg1 = tf.concat((xg1, xg1_1), -1)
        # xg1 = xg1_1
        # xl = tf.nn.relu(self.layer2(xl))
        # x = tf.concat((xg1, xl), -1)
        x = xg1
        x = self.layer3(x)
        x = self.layer4(x)
        print(x.shape)
        return x


class ORBIT5K_CNN_PLLay(tf.keras.Model):
    def __init__(self, name='orbit5kcnnpllay', filters=32, kernel_size=4, unitsDense=64, unitsTopInput=64, unitsTopMiddle=64, **kwargs):
        super(ORBIT5K_CNN_PLLay, self).__init__(**kwargs)
        self.layer1_1 = tf.keras.layers.Conv2D(filters, kernel_size, padding="same", activation='relu')
        self.layer1_2 = tf.keras.layers.Conv2D(1, kernel_size, padding="same", activation='relu')
        self.layer1_3 = TopoFunLayer(unitsTopMiddle, grid_size=[40, 40], tseq=np.linspace(0.05, 0.95, 18), KK=list(range(2)), dimensions = [0, 1])
        # self.layer2 = TopoLayer(unitsTopInput, m0=0.02, tseq=np.linspace(0.03, 0.1, 17), KK=list(range(2)), dimensions = [0, 1], lims = [[0.0125, 0.9875], [0.0125, 0.9875]], by=0.025)
        self.layer2 = GThetaLayer(unitsTopInput)
        self.layer3 = tf.keras.layers.Dense(unitsDense, activation='relu', name='dense_2') 
        self.layer4 = tf.keras.layers.Dense(5, name='predictions')

    def call(self, x):
        xg, xl, xd = tf.split(x, [1600, 102, 4*nmax_diag], axis=-1)
        xg = tf.reshape(xg, [16, 40, 40, 1])
        xg1 = self.layer1_1(xg)
        xg1 = self.layer1_2(xg1)
        xg1 = tf.reshape(xg1, [16, 1600])
        xg1_1 = tf.nn.relu(self.layer1_3(xg1))
        xg1 = tf.concat((xg1, xg1_1), -1)
        # xg1 = xg1_1
        xl = tf.nn.relu(self.layer2(xl))
        x = tf.concat((xg1, xl), -1)
        # x = xg1
        x = self.layer3(x)
        x = self.layer4(x)
        print(x.shape)
        return x
  

class ORBIT5K_CNN_PLLay_input(tf.keras.Model):
    def __init__(self, name='orbit5kcnnpllayinput', filters=32, kernel_size=4, unitsDense=64, unitsTopInput=64, **kwargs):
        super(ORBIT5K_CNN_PLLay_input, self).__init__(**kwargs)
        self.layer1_1 = tf.keras.layers.Conv2D(filters, kernel_size, padding="same", activation='relu')
        self.layer1_2 = tf.keras.layers.Conv2D(1, kernel_size, padding="same", activation='relu')
        # self.layer1_3 = TopoFunLayer(unitsTopMiddle, grid_size=[40, 40], tseq=np.linspace(0.05, 0.95, 18), KK=list(range(2)), dimensions = [0, 1])
        # self.layer2 = TopoLayer(unitsTopInput, m0=0.02, tseq=np.linspace(0.03, 0.1, 17), KK=list(range(2)), dimensions = [0, 1], lims = [[0.0125, 0.9875], [0.0125, 0.9875]], by=0.025)
        self.layer2 = GThetaLayer(unitsTopInput)
        self.layer3 = tf.keras.layers.Dense(unitsDense, activation='relu', name='dense_2') 
        self.layer4 = tf.keras.layers.Dense(5, name='predictions')

    def call(self, x):
        xg, xl, xd = tf.split(x, [1600, 102, 4*nmax_diag], axis=-1)
        xg = tf.reshape(xg, [16, 40, 40, 1])
        xg1 = self.layer1_1(xg)
        xg1 = self.layer1_2(xg1)
        xg1 = tf.reshape(xg1, [16, 1600])
        # xg1_1 = tf.nn.relu(self.layer1_3(xg1))
        # xg1 = tf.concat((xg1, xg1_1), -1)
        # xg1 = xg1_1
        xl = tf.nn.relu(self.layer2(xl))
        x = tf.concat((xg1, xl), -1)
        # x = xg1
        x = self.layer3(x)
        x = self.layer4(x)
        print(x.shape)
        return x

def split_train_valid_test(X, X_grid, y, random_state, batch_size=16):

    # Train validate test split
    iX_train, iX_test, y_train, y_test = train_test_split(list(range(len(y))),
          y, test_size=0.3, random_state = random_state, shuffle = True,
          stratify = y)
    iX_train, iX_val, y_train, y_val = train_test_split(iX_train, y_train,
          test_size=0.1, random_state = random_state, shuffle = True,
          stratify = y_train)

    train_dataset = to_tf_dataset(x=X[iX_train], y=y_train,
          batch_size=batch_size)
    val_dataset = to_tf_dataset(x=X[iX_val], y=y_val, batch_size=batch_size)
    test_dataset = to_tf_dataset(x=X[iX_test], y=y_test, batch_size=batch_size)
    train_dataset_grid = to_tf_dataset(x=X_grid[iX_train], y=y_train,
          batch_size=batch_size)
    val_dataset_grid = to_tf_dataset(x=X_grid[iX_val], y=y_val,
          batch_size=batch_size)
    test_dataset_grid = to_tf_dataset(x=X_grid[iX_test], y=y_test,
          batch_size=batch_size)

    return (train_dataset, val_dataset, test_dataset, train_dataset_grid,
          val_dataset_grid, test_dataset_grid)


def orbit5k_train(nTimes, epochs, es, rand_state, noise_prob_list,
      X_processed_file_list, X_grid_processed_file_list, y_file,
      model_mlp_file_array, model_mlp_pllay_file_array, model_cnn_file_array,
      model_cnn_pllay_file_array, model_cnn_pllay_input_file_array,
      batch_size=16):
    
    start_time = time.time()

    print("epochs = ", epochs)
    print("nTimes = ", nTimes)
    print("random states = ", rand_state)

    y = np.load(y_file)

    for iNoise in range(nNoise):

        print("--------------------------------------------------------------")
        print("Noise rate = ", noise_prob_list[iNoise])
        print("--------------------------------------------------------------")
        X_processed = np.load(X_processed_file_list[iNoise])
        X_grid_processed = np.load(X_grid_processed_file_list[iNoise])
        # (X_noiseWithLandscape, X_noiseGridWithLandscape)= generateDataset(X = X, noise_prob = noise_prob,
        #                                                                 num_orbit_per_param=num_orbit_per_param,
        #                                                                 num_pts_per_orbit=num_pts_per_orbit,
        #                                                                 m0=m0, lims=lims, by=by, r=r,
        #                                                                 tseq=tseq, KK=KK, dimensions = dimensions)

        for iTime in range(nTimes):

            # Train validate test split
            (train_dataset, val_dataset, test_dataset, train_dataset_grid, val_dataset_grid, test_dataset_grid) = split_train_valid_test(
                  X=X_processed, X_grid=X_grid_processed, y=y,
                  random_state=rand_state[iTime], batch_size=batch_size)

            #MLP
            start_time_inside = time.time()
            np.random.seed(rand_state[iTime])
            tf.random.set_seed(rand_state[iTime])
            print("MLP")
            model_mlp = ORBIT5K_MLP()
            model_mlp.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            hist_mlp = model_mlp.fit(train_dataset, epochs=epochs,
                  callbacks=[es], validation_data=val_dataset)
            model_mlp.save_weights(model_mlp_file_array[iNoise][iTime])
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            #MLP + PLLay
            start_time_inside = time.time()
            np.random.seed(rand_state[iTime])
            tf.random.set_seed(rand_state[iTime])
            print("MLP + PLLay")
            model_mlp_pllay = ORBIT5K_MLP_PLLay()
            model_mlp_pllay.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            hist_mlp_pllay = model_mlp_pllay.fit(train_dataset, epochs=epochs,
                  callbacks=[es], validation_data=val_dataset)
            model_mlp_pllay.save_weights(
                  model_mlp_pllay_file_array[iNoise][iTime])
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            # CNN
            start_time_inside = time.time()
            np.random.seed(rand_state[iTime])
            tf.random.set_seed(rand_state[iTime])
            print("CNN")
            model_cnn = ORBIT5K_CNN()
            model_cnn.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            hist_cnn = model_cnn.fit(train_dataset_grid, epochs=epochs,
                  callbacks=[es], validation_data=val_dataset_grid)
            model_cnn.save_weights(model_cnn_file_array[iNoise][iTime])
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            #CNN + PLLay
            start_time_inside = time.time()
            np.random.seed(rand_state[iTime])
            tf.random.set_seed(rand_state[iTime])
            print("CNN + PLLay")
            model_cnn_pllay = ORBIT5K_CNN_PLLay()
            model_cnn_pllay.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            hist_cnn_pllay = model_cnn_pllay.fit(train_dataset_grid,
                  epochs=epochs, callbacks=[es],
                  validation_data=val_dataset_grid)
            model_cnn_pllay.save_weights(
                  model_cnn_pllay_file_array[iNoise][iTime])
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            #CNN + PLLay, input only
            start_time_inside = time.time()
            np.random.seed(rand_state[iTime])
            tf.random.set_seed(rand_state[iTime])
            print("CNN + PLLay, input only")
            model_cnn_pllay_input = ORBIT5K_CNN_PLLay_input()
            model_cnn_pllay_input.compile(
                  optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            hist_cnn_pllay_input = model_cnn_pllay_input.fit(
                  train_dataset_grid, epochs=epochs, callbacks=[es],
                  validation_data=val_dataset_grid)
            model_cnn_pllay_input.save_weights(
                  model_cnn_pllay_input_file_array[iNoise][iTime])
            print("--- %s seconds ---" % (time.time() - start_time_inside))

        print("--------------------------------------------------------------")
        print("--- %s seconds ---" % (time.time() - start_time))
        print("--------------------------------------------------------------")

# noise_prob_list = [0.1]
noise_prob_list = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]
nNoise = len(noise_prob_list)
file_noise_list = [None] * nNoise
for iNoise in range(nNoise):
    file_noise_list[iNoise] = str(int(noise_prob_list[iNoise] * 100)).zfill(2)

X_processed_file_list = [None] * nNoise
for iNoise in range(nNoise):
    X_processed_file_list[iNoise] = (
          'orbit5k_X_processed_' + file_noise_list[iNoise] + '.npy')
X_grid_processed_file_list = [None] * nNoise
for iNoise in range(nNoise):
    X_grid_processed_file_list[iNoise] = (
          'orbit5k_X_grid_processed_' + file_noise_list[iNoise] + '.npy')
y_file = 'orbit5k_y.npy'

# nTimes=1
nTimes=10
model_mlp_file_array = [None] * nNoise
model_mlp_pllay_file_array = [None] * nNoise
model_cnn_file_array = [None] * nNoise
model_cnn_pllay_file_array = [None] * nNoise
model_cnn_pllay_input_file_array = [None] * nNoise
for iNoise in range(nNoise):
    model_mlp_file_array[iNoise] = [None] * nTimes
    model_mlp_pllay_file_array[iNoise] = [None] * nTimes
    model_cnn_file_array[iNoise] = [None] * nTimes
    model_cnn_pllay_file_array[iNoise] = [None] * nTimes
    model_cnn_pllay_input_file_array[iNoise] = [None] * nTimes
for iNoise in range(nNoise):
    for iTime in range(nTimes):
        file_time = str(iTime).zfill(2)
        model_mlp_file_array[iNoise][iTime] = 'orbit5k_models/mlp_' + \
              file_noise_list[iNoise] + '_' + file_time + '/model'
        model_mlp_pllay_file_array[iNoise][iTime] = \
              'orbit5k_models/mlp_pllay_' + file_noise_list[iNoise] + '_' + \
              file_time + '/model'
        model_cnn_file_array[iNoise][iTime] = 'orbit5k_models/cnn_' + \
              file_noise_list[iNoise] + '_' + file_time + '/model'
        model_cnn_pllay_file_array[iNoise][iTime] = \
              'orbit5k_models/cnn_pllay_' + file_noise_list[iNoise] + '_' + \
              file_time + '/model'
        model_cnn_pllay_input_file_array[iNoise][iTime] = \
              'orbit5k_models/cnn_pllay_input_' + file_noise_list[iNoise] + \
              '_' + file_time + '/model'

batch_size=16

# epochs=10
epochs=100
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.003,
      patience=3, verbose=1)

np.random.seed(0)
rand_state = [np.random.randint(2**16) for iTimes in range(nTimes)]
# rand_state = (
#       [2732, 43567, 42613, 52416, 45891, 21243, 30403, 32103, 41993, 57043])

orbit5k_train(nTimes=nTimes, epochs=epochs, es=es, rand_state=rand_state,
      noise_prob_list=noise_prob_list,
      X_processed_file_list=X_processed_file_list,
      X_grid_processed_file_list=X_grid_processed_file_list, y_file=y_file,
      model_mlp_file_array=model_mlp_file_array,
      model_mlp_pllay_file_array=model_mlp_pllay_file_array,
      model_cnn_file_array=model_cnn_file_array,
      model_cnn_pllay_file_array=model_cnn_pllay_file_array,
      model_cnn_pllay_input_file_array=model_cnn_pllay_input_file_array,
      batch_size=batch_size)